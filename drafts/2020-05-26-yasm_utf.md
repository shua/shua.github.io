<pmeta id="created">2020 May 26</pmeta>
<pmeta id="title">yasm utf string ops</pmeta>

From the previous work in UEFI images, I got a new itch: extend [`yasm`] to support
[`nasm`'s utf string ops].

For a minimal example, I wanted to write
```
; example.s
dw __utf16be__("hello")
```

and have
```
$ yasm example.s  -o example.out
$ od example.out -x
0000000 0068 0065 006c 006c 006f
```

Digging
-------
`yasm` is a C codebase that's currently split into a frontend and a backend.
The "frontend" encompasses the tokenization and parsing of source code,
and the "backend" encompasses assembling codes and data into an object file.

My change would need two things implemented:
- recognizing and parsing the `__utf*__` ops correctly
- translating the utf8 encoded string in the string op to some other unicode encoding

the first naturally fits in the "frontend" code, and the second in the "backend".

Parsing
-------
`yasm` uses a cool preprocessor called "re2c" to generate its tokenizer as C source.
I'd never heard of it before, but the tool reads essentially annotated C source and generates
some state machine code code from the annotations.

I've used `yacc` and the like to produce parsers for toy langs before,
and the theory is very similar, but re2c seems a little closer to a pure C state machine parser.
I think it's pretty neat, and while many modern languages cry about extensibility,
it's kind of a self-inflicted problem with programmers who are uncomfortable 
writing parsers, preprocessors, and code generators.
Source code is (usually) just text, so every language can be seen as just a
compile target for a slightly more powerful language.

Anyway, I'm only interested in extending the nasm parser, so changes go in
`modules/parsers/nasm` where I added a new token type of `STRING_OP` that is
emitted by any matches on `__utf*__`  style prefixes.
Next I added parsing rules that `STRING_OP` should be proceeded by `'(' STRING ')'`.
When that sequence of tokens is matched, a new data value is created with the
value of the `STRING` token is encoded according to the `STRING_OP`.
The actual encoding is done by some "backend" code.

Encoding
--------
I used [unicode's documentation] as well the helpful [w3m documentation]
on different unicode encoding and decoding schemes.
I won't recreate the specifics here, but the higher-level was
1. if the output is utf8, then just copy input to a dataval object and return that
2. set `utfenc` to the proper (16/32bit) encoding function, and `be` to true/false depending on if the encoding is big-endian or not
3. if there's no more input, then create the dataval from the buffer and return it
4. else decode a 32bit codepoint from input
5. encode the codepoint using `utfenc` and `be` and append to the buffer
6. go back to 3

If you want to read the actual implementation it's available currently on a branch.

Testing
-------
I really wanted an automated way to test this things worked as I expected,
luckily the yasm project has some testing setup I could use.
I found it a bit tricky to get setup and running, and was basically compiling
the testing code and running them manually because I couldn't get the whole
test running scripts to work.

Eventually I _was_ able to get the tests running, and added my own to exercise
the code I had added and written.
I only tested the happy cases of each string op, and I didn't manage to find
meaningful codepoints to test surrogate pairing in utf16\* encodings or longer
utf8 clusters.
I have no reason to believe it _won't_ work for higher codepoints,
but they're currently not tested.

Similarly, no idea if I added a data leak or not.
The parser code, and some of the backend code does allocations and frees
that were throwing me off, and it's unclear to me who owns what data
that get's passed around, caller or callee.

The PR
------
There's [a PR] open to add this feature to yasm, but I haven't seen a lot of
movement on that codebase or the PRs, so I don't have a lot of hope for it.
While this was a fun dive into a foreign codebase, I wonder if people are
using some other opensource nasm-like assembler, and that's why development
on yasm has stagnated.

Some Corollary Thoughts
-----------------------
It was a nice stretch, and along the way I cemented a couple insights into myself:
The first is that I really like reading and implementing clear specs.
I guess the alternative is just hacking something together, and I like that too,
but there's an enjoyment I get from perusing the encoding/decoding specs in
unicode that I really miss in hack projects.

The second is related to the `re2c` program used in the yasm source and is 
more a _feely_ thing in that that I am comforted knowing that I can extend 
any language I want to by writing preprocessors and compilers for more 
interesting languages on top of it.
I mostly write Java in my day job, and it feels like so much work to get
cultural acceptance of Lombok, much less custom preprocessors or code
generators to improve our day-to-day.
When I try higher-level languages it _feels_ like the abstractions on the 
lower-level were chosen by someone else, and isn't really what I'm looking for,
but I guess it'll do, and hey it's better than asm or C.
In addition, especially with higher-level langs like haskell, scala, ocaml, or prolog;
I enjoy them for different reasons, specifically when I want to stretch my
"math brain".
But they do not stretch my "computer brain", the part of me that wants to program
a computer, not describe a relation.

I like building *my own* abstractions from the ground up, and while I wouldn't
want to burden another person with whatever frankenlang I've created,
it really helps me to feel like I know what's going on *semantically* with the source.
Like I really get the meaning of a word when I've defined it,
or the meaning of a specific syntactical construct when I made all the parsing
rules for it and considered a bunch of alternatives, but this is the one that
made the most sense *to me*.
I guess it's not really a revalation that implementing things by hand gives
you a better understanding of other implementations, or that it produces
something that resonates better with you than other implementations.

Having leaned into Rust a little more, and weirdly doing a lot of prolog
on the side, I still like C, and I really like the idea, however burdensome,
of extending that to do what I want, instead of jumping to a higher-level
language just to use a couple things I don't understand.

**-JD**

[`yasm`]:
[`nasm`]:
[unicode's documentation]:
[w3m documentation]:
[a PR]:
